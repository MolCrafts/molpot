{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'molpot.logging'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mload_ext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mautoreload\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mautoreload\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmolpot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpot\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mignite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Events\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\chinczyk\\molpot\\src\\molpot\\__init__.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m App\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01munit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unit, get_unit\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config, Config\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malias\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alias, NameSpace\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'molpot.logging'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import molpot as mpot\n",
    "import torch\n",
    "from ignite.engine.events import Events\n",
    "from ignite.metrics import MeanAbsoluteError, MetricUsage\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_training_process(node=64, depth=4, nbasis=10):\n",
    "        \n",
    "        config = mpot.Config()\n",
    "        config.set_device(\"cuda\")\n",
    "\n",
    "        pinet = mpot.nnp.PiNet2(\n",
    "            depth=depth,\n",
    "            basis_fn=mpot.nnp.radial.GaussianRBF(nbasis, 4.5),\n",
    "            cutoff_fn=mpot.nnp.cutoff.CosineCutoff(4.5),\n",
    "            pi_nodes=[node, node],\n",
    "            ii_nodes=[node, node, node, node],\n",
    "            pp_nodes=[node, node, node, node],\n",
    "            activation=torch.nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        e_readout = mpot.nnp.base.Batchwise(\n",
    "            n_neurons=[node, node, 1],\n",
    "            in_key=(\"pinet\", \"p1\"),\n",
    "            out_key=\"energy\",\n",
    "            reduce=\"sum\",\n",
    "        )\n",
    "        f_readout = mpot.nnp.base.PairForce(in_key=(\"pinet\", \"p1\"), out_key=\"forces\")\n",
    "        potential = mpot.potential.PotentialSeq(pinet, e_readout, f_readout)\n",
    "\n",
    "        optimizer = torch.optim.Adam(potential.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.994)\n",
    "        loss_fn = mpot.Constraint()\n",
    "        loss_fn.add(\"energy\", torch.nn.MSELoss(), \"energy\", \"energy\", 1.0)\n",
    "        loss_fn.add(\"forces\", torch.nn.MSELoss(), \"forces\", \"forces\", 10.0)\n",
    "        lwscheduler = mpot.engine.loss.ExponentialLW(\n",
    "            loss_fn.get_constraint(\"forces\"), gamma=0.99\n",
    "        )\n",
    "\n",
    "        trainer = mpot.PotentialTrainer(\n",
    "            model=potential,\n",
    "            optimizer=optimizer,\n",
    "            loss_fn=loss_fn,\n",
    "            device=config.device,\n",
    "        )\n",
    "        trainer.compile()\n",
    "        trainer.add_lr_scheduler(scheduler)\n",
    "        trainer.add_lw_scheduler(lwscheduler)\n",
    "        # trainer.add_checkpoint(\"ckpt\")\n",
    "\n",
    "        train_metric_usage = MetricUsage(\n",
    "            started=Events.ITERATION_STARTED(every=100),\n",
    "            iteration_completed=Events.ITERATION_COMPLETED,\n",
    "            completed=Events.ITERATION_COMPLETED(every=100),\n",
    "        )\n",
    "        eval_metric_usage = MetricUsage(\n",
    "            started=Events.EPOCH_STARTED,\n",
    "            iteration_completed=Events.ITERATION_COMPLETED,\n",
    "            completed=Events.EPOCH_COMPLETED,\n",
    "        )\n",
    "\n",
    "        trainer.set_metric_usage(\n",
    "            trainer=train_metric_usage, evaluator=eval_metric_usage\n",
    "        )\n",
    "\n",
    "        trainer.add_metric(\n",
    "            \"e_mae\",\n",
    "            lambda: MeanAbsoluteError(\n",
    "                output_transform=lambda x: (\n",
    "                    x[\"predicts\", \"energy\"],\n",
    "                    x[\"labels\", \"energy\"],\n",
    "                ),\n",
    "                device=config.device,\n",
    "            ),\n",
    "        )\n",
    "        trainer.add_metric(\n",
    "            \"f_mae\",\n",
    "            lambda: MeanAbsoluteError(\n",
    "                output_transform=lambda x: (\n",
    "                    x[\"predicts\", \"forces\"],\n",
    "                    x[\"labels\", \"forces\"],\n",
    "                ),\n",
    "                device=config.device,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # trainer.attach_tensorboard(log_dir=\"tblog\")\n",
    "        return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataloader(ds_path, molecule):\n",
    "\n",
    "    rmd17_ds = mpot.dataset.rMD17(ds_path, molecule=molecule)\n",
    "    rmd17_ds.prepare(total=1000, preprocess=[mpot.process.NeighborList(cutoff=5.0)])\n",
    "\n",
    "    train_ds, eval_ds = torch.utils.data.random_split(rmd17_ds, [0.95, 0.05])\n",
    "    train_dl = mpot.DataLoader(train_ds, batch_size=10)\n",
    "    eval_dl = mpot.DataLoader(eval_ds, batch_size=1)\n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(mpot.App):\n",
    "\n",
    "    def cmd_run(self, ds_path: str, molecule: str, max_steps: int):\n",
    "\n",
    "        train_dl, eval_dl = define_dataloader(ds_path, molecule)\n",
    "        trainer = define_training_process(train_dl, eval_dl)\n",
    "        trainer.run(train_data=train_dl, max_steps=max_steps, eval_data=eval_dl)\n",
    "\n",
    "    def cmd_run_with_config(self, config_path):\n",
    "        config = self.load_config(config_path)\n",
    "        train_dl, eval_dl = define_dataloader(config['ds_path'], config['molecule'])\n",
    "        trainer = define_training_process(train_dl, eval_dl)\n",
    "        trainer.run(train_data=train_dl, max_steps=config['max_steps'], eval_data=eval_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = TrainModel()\n",
    "app.cmd_run(\"/workspaces/train_pot/data/rmd17\", \"aspirin\", \"1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "state = None\n",
    "\n",
    "\n",
    "class TuningModel(mpot.App):\n",
    "\n",
    "    def cmd_run(self, ds_path: str, molecule: str, n_trials: int):\n",
    "        study_name = f\"tuning_{molecule}\"\n",
    "        study = optuna.create_study(\n",
    "            study_name=study_name, storage=\"sqlite:///tuning.db\", load_if_exists=True\n",
    "        )\n",
    "\n",
    "        train_dl, eval_dl = define_dataloader(\n",
    "            ds_path,\n",
    "            molecule,\n",
    "        )\n",
    "\n",
    "        def objective(trial):\n",
    "            global state\n",
    "            node = trial.suggest_int(\"node\", 16, 64, step=16)\n",
    "            trainer = define_training_process(node=node)\n",
    "            state = trainer.run(train_data=train_dl, max_steps=101, eval_data=None)\n",
    "            return state.metrics[\"e_mae\"]\n",
    "\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        return study\n",
    "\n",
    "\n",
    "app = TuningModel()\n",
    "study = app.cmd_run(\"/workspaces/train_pot/data/rmd17\", \"aspirin\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import burr\n",
    "\n",
    "class BatchTrainModel(mpot.App):\n",
    "    ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
